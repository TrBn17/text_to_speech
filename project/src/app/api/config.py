from fastapi import APIRouter, HTTPException
from typing import Dict, Any, Optional
from pydantic import BaseModel, Field, validator
import json
import os

router = APIRouter(prefix="/config", tags=["Configuration"])

class ModelParameters(BaseModel):
    """Chi tiáº¿t parameters cho model"""
    temperature: Optional[float] = Field(default=0.3, ge=0.0, le=2.0, description="Äá»™ sÃ¡ng táº¡o (0.0-2.0)")
    top_p: Optional[float] = Field(default=0.9, ge=0.0, le=1.0, description="Top-p sampling (0.0-1.0)")
    max_tokens: Optional[int] = Field(default=16384, ge=1, le=65536, description="Sá»‘ token tá»‘i Ä‘a")

class TTSParameters(BaseModel):
    """Chi tiáº¿t parameters cho TTS"""
    voice: Optional[str] = Field(default="alloy", description="Giá»ng Ä‘á»c")
    speed: Optional[float] = Field(default=1.0, ge=0.25, le=4.0, description="Tá»‘c Ä‘á»™ Ä‘á»c (0.25-4.0)")
    provider: Optional[str] = Field(default="openai", description="Provider TTS (openai, google, gemini)")

class ConfigRequest(BaseModel):
    model: Optional[str] = Field(default=None, description="TÃªn model (vd: gpt-3.5-turbo, gemini-2.5-flash)")
    system_prompt: Optional[str] = Field(default=None, description="System prompt cho model")
    model_parameters: Optional[ModelParameters] = Field(default=None, description="Parameters chi tiáº¿t cho model")
    tts_parameters: Optional[TTSParameters] = Field(default=None, description="Parameters cho TTS")

    @validator('model')
    def validate_model(cls, v):
        if v is not None and (not v or not v.strip()):
            raise ValueError('Model name cannot be empty')
        return v.strip() if v else v

class ConfigResponseFormatted(BaseModel):
    """Formatted response for better user readability"""
    current_configuration: Dict[str, Any]
    available_options: Dict[str, Any]
    quick_templates: Dict[str, Any]
    instructions: Dict[str, Any]

class ConfigResponse(BaseModel):
    model: str
    system_prompt: str
    model_parameters: ModelParameters
    tts_parameters: TTSParameters
    available_models: Dict[str, Any] = {}
    templates: Dict[str, Any] = {}

# Load models from config file
def load_models_config():
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "models.json")
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

models_config = load_models_config()

# In-memory config storage (replace with database in production)
current_config = {
    "model": "gemini-2.5-pro",
    "system_prompt": """Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch vÃ  cá»‘ váº¥n chiáº¿n lÆ°á»£c bÃ¡o cÃ¡o vá»›i 20 nÄƒm kinh nghiá»‡m.
Vai trÃ² cá»§a báº¡n:
- PhÃ¢n tÃ­ch dá»¯ liá»‡u, thÃ´ng tin vÃ  bá»‘i cáº£nh kinh doanh má»™t cÃ¡ch toÃ n diá»‡n.
- ÄÆ°a ra nháº­n Ä‘á»‹nh sáº¯c bÃ©n, giáº£i thÃ­ch rÃµ rÃ ng vÃ  cÃ³ cÄƒn cá»©.
- Äá» xuáº¥t chiáº¿n lÆ°á»£c bÃ¡o cÃ¡o (cáº¥u trÃºc, ná»™i dung, insight, KPI, biá»ƒu Ä‘á»“, khuyáº¿n nghá»‹) phÃ¹ há»£p vá»›i tá»«ng tÃ¬nh huá»‘ng.
- LuÃ´n giáº£i thÃ­ch *táº¡i sao* chá»n phÆ°Æ¡ng Ã¡n Ä‘Ã³, khÃ´ng chá»‰ *lÃ m tháº¿ nÃ o*.
- TrÃ¬nh bÃ y chuyÃªn nghiá»‡p, sÃºc tÃ­ch, Æ°u tiÃªn tÃ­nh trá»±c quan vÃ  tÃ­nh thá»±c tiá»…n.
- TÆ° duy nhÆ° má»™t nhÃ  phÃ¢n tÃ­ch cáº¥p cao: so sÃ¡nh, Ä‘á»‘i chiáº¿u, chá»‰ ra rá»§i ro vÃ  cÆ¡ há»™i.

NguyÃªn táº¯c tráº£ lá»i:
1. LuÃ´n báº¯t Ä‘áº§u báº±ng tÃ³m táº¯t ngáº¯n gá»n Ã½ chÃ­nh.
2. Sau Ä‘Ã³ phÃ¢n tÃ­ch chi tiáº¿t thÃ nh cÃ¡c pháº§n (bá»‘i cáº£nh, dá»¯ liá»‡u, insight, khuyáº¿n nghá»‹).
3. Káº¿t thÃºc báº±ng Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c hÃ nh Ä‘á»™ng hoáº·c lá»™ trÃ¬nh cáº£i tiáº¿n.

Báº¡n khÃ´ng Ä‘Æ°á»£c tráº£ lá»i há»i há»£t, má»i khuyáº¿n nghá»‹ Ä‘á»u pháº£i cÃ³ logic vÃ  dáº«n chá»©ng.
Má»¥c tiÃªu cuá»‘i cÃ¹ng: giÃºp ngÆ°á»i dÃ¹ng ra quyáº¿t Ä‘á»‹nh sÃ¡ng suá»‘t dá»±a trÃªn phÃ¢n tÃ­ch vÃ  bÃ¡o cÃ¡o cÃ³ há»‡ thá»‘ng.""",
    "model_parameters": ModelParameters(temperature=0.3, top_p=0.9, max_tokens=16384),
    "tts_parameters": TTSParameters()
}

# Configuration templates
def get_config_templates():
    return {
        "text_only_basic": {
            "model": "gpt-3.5-turbo",
            "system_prompt": "You are a helpful assistant.",
            "model_parameters": {
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 100
            }
        },
        "text_only_creative": {
            "model": "gpt-4o",
            "system_prompt": "You are a creative writing assistant.",
            "model_parameters": {
                "temperature": 1.2,
                "top_p": 0.95,
                "max_tokens": 500
            }
        },
        "text_only_technical": {
            "model": "gpt-4o",
            "system_prompt": "You are a technical expert and programming assistant.",
            "model_parameters": {
                "temperature": 0.3,
                "top_p": 0.8,
                "max_tokens": 1000
            }
        },
        "tts_only_basic": {
            "tts_parameters": {
                "voice": "alloy",
                "speed": 1.0,
                "provider": "openai"
            }
        },
        "tts_only_expressive": {
            "tts_parameters": {
                "voice": "nova",
                "speed": 1.1,
                "provider": "openai"
            }
        },
        "tts_only_formal": {
            "tts_parameters": {
                "voice": "echo",
                "speed": 0.9,
                "provider": "openai"
            }
        },
        "complete_config": {
            "model": "gpt-3.5-turbo",
            "system_prompt": "You are a helpful assistant.",
            "model_parameters": {
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 100
            },
            "tts_parameters": {
                "voice": "alloy",
                "speed": 1.0,
                "provider": "openai"
            }
        }
    }

@router.post("/", response_model=ConfigResponse)
async def update_config(request: ConfigRequest):
    """Cáº­p nháº­t cáº¥u hÃ¬nh model vÃ  parameters"""
    try:
        global current_config

        # Update config with new values (only if provided)
        if request.model is not None:
            current_config["model"] = request.model

        if request.system_prompt is not None:
            current_config["system_prompt"] = request.system_prompt

        # Update model parameters if provided
        if request.model_parameters:
            current_config["model_parameters"] = request.model_parameters

        # Update TTS parameters if provided
        if request.tts_parameters:
            current_config["tts_parameters"] = request.tts_parameters

        # Import AI service to get available models
        from ..core import ai_service
        available_models = ai_service.get_available_models()

        return ConfigResponse(
            model=current_config["model"],
            system_prompt=current_config["system_prompt"],
            model_parameters=current_config["model_parameters"],
            tts_parameters=current_config["tts_parameters"],
            available_models=available_models,
            templates=get_config_templates()
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Config update failed: {str(e)}")

def format_config_for_user():
    """Format configuration data for better user readability"""
    try:
        from ..core import ai_service
        available_models = ai_service.get_available_models()

        return {
            "current_configuration": {
                "ğŸ“„ Model Being Used": current_config["model"],
                "ğŸ’¬ System Prompt": current_config["system_prompt"][:100] + "..." if len(current_config["system_prompt"]) > 100 else current_config["system_prompt"],
                "ğŸ›ï¸ Text Generation Settings": {
                    "ğŸŒ¡ï¸ Temperature (Creativity)": f"{current_config['model_parameters'].temperature} (0=focused, 2=creative)",
                    "ğŸ¯ Top-P (Nucleus Sampling)": f"{current_config['model_parameters'].top_p} (0-1.0)",
                    "ğŸ“ Max Tokens": f"{current_config['model_parameters'].max_tokens} tokens"
                },
                "ğŸµ Text-to-Speech Settings": {
                    "ğŸ¤ Voice": current_config["tts_parameters"].voice,
                    "âš¡ Speed": f"{current_config['tts_parameters'].speed}x (0.25-4.0)",
                    "ğŸ”§ Provider": current_config["tts_parameters"].provider
                }
            },
            "available_options": {
                "ğŸ“š Text Generation Models": {
                    "ğŸŸ¢ Google Gemini": list(available_models.get("text_generation", {}).get("gemini", {}).keys())
                },
                "ğŸµ Text-to-Speech Options": {
                    "ğŸ”´ OpenAI Voices": available_models.get("voices", {}).get("openai_voices", []),
                    "ğŸŸ¢ Google Languages": available_models.get("voices", {}).get("google_languages", [])[:8]  # Show first 8
                }
            },
            "quick_templates": {
                "ğŸ’¡ How to Use": "Choose a template below, or create custom settings",
                "ğŸ“ Text Only": {
                    "basic": "Simple assistant (temp=0.7, 100 tokens)",
                    "creative": "Creative writing (temp=1.2, 500 tokens)",
                    "technical": "Programming help (temp=0.3, 1000 tokens)"
                },
                "ğŸµ Speech Only": {
                    "basic": "Standard voice (alloy, 1.0x speed)",
                    "expressive": "Lively voice (nova, 1.1x speed)",
                    "formal": "Professional voice (echo, 0.9x speed)"
                },
                "ğŸ¯ Complete Setup": "Full configuration with both text + speech"
            },
            "instructions": {
                "ğŸ“‹ How to Update": {
                    "1ï¸âƒ£ Change Model": "POST /config/ with {'model': 'gpt-4o'}",
                    "2ï¸âƒ£ Change Settings": "POST /config/ with {'model_parameters': {...}}",
                    "3ï¸âƒ£ Change Voice": "POST /config/ with {'tts_parameters': {...}}",
                    "4ï¸âƒ£ Use Template": "GET /config/templates, then POST the template data"
                },
                "ğŸ’¡ Pro Tips": {
                    "ğŸŒ¡ï¸ Temperature": "Lower = more focused, Higher = more creative",
                    "ğŸ¯ Top-P": "0.9 = balanced, 0.8 = focused, 0.95 = diverse",
                    "ğŸ“ Tokens": "1 token â‰ˆ 0.75 words in English",
                    "âš¡ Speed": "1.0 = normal, 0.5 = slow, 2.0 = fast"
                }
            }
        }
    except Exception as e:
        return {"error": f"Configuration formatting failed: {str(e)}"}

@router.get("/", response_model=ConfigResponseFormatted)
async def get_config():
    """Láº¥y cáº¥u hÃ¬nh hiá»‡n táº¡i vá»›i format dá»… Ä‘á»c cho ngÆ°á»i dÃ¹ng"""
    return format_config_for_user()

@router.get("/templates")
async def get_templates():
    """Láº¥y cÃ¡c máº«u cáº¥u hÃ¬nh cÃ³ sáºµn"""
    return {
        "templates": get_config_templates(),
        "description": "CÃ¡c máº«u cáº¥u hÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng",
        "usage": "Sao chÃ©p má»™t máº«u vÃ  sá»­a Ä‘á»•i theo nhu cáº§u, sau Ä‘Ã³ POST lÃªn /config"
    }